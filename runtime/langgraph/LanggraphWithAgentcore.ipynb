{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **AI Candidate Screening Agent using Amazon Bedrock AgentCore Runtime, Langgraph/Langchain and Gemini 2.5 Flash**"
      ],
      "metadata": {
        "id": "6GTjljCnTyEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This agent help you analyze your CV against the job requirements, provide result for the next recruitment step, create rejection/interview email and create interview question."
      ],
      "metadata": {
        "id": "BvMZsId78YcF"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79d8c7d5"
      },
      "source": [
        "import os\n",
        "# Retrieve AWS credentials from Colab Secrets\n",
        "from google.colab import userdata\n",
        "os.environ['AWS_ACCESS_KEY_ID'] = userdata.get('AWSACCESSKEY')\n",
        "os.environ['AWS_SECRET_ACCESS_KEY'] = userdata.get('AWSSECRETKEY')\n",
        "# Create the folder\n",
        "folder_name = \"runtime\"\n",
        "os.makedirs(folder_name, exist_ok=True)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile runtime/requirements.txt\n",
        "bedrock-agentcore-starter-toolkit\n",
        "bedrock-agentcore\n",
        "langgraph\n",
        "google-genai\n",
        "pypdf\n",
        "boto3\n",
        "langchain[google-genai]\n",
        "pydantic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGnKDvmuns72",
        "outputId": "f9d5b0a0-8b60-4cf6-a44f-ca78b21fa0c6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing runtime/requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vnCQ4jjTtkF"
      },
      "outputs": [],
      "source": [
        "!pip install -r runtime/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile runtime/langgraph_agentcore.py\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain.agents import create_agent\n",
        "from langgraph.graph import StateGraph, START, END, MessagesState\n",
        "from langgraph.types import Command\n",
        "from langchain_core.messages import AIMessage\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Optional\n",
        "import boto3\n",
        "import datetime\n",
        "import json\n",
        "import random\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "# Exclusive deploy to AgentCore Runtime\n",
        "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
        "app = BedrockAgentCoreApp()\n",
        "\n",
        "region = \"us-west-2\"\n",
        "s3 = boto3.client('s3', region_name=region)\n",
        "\n",
        "# Retrieve Gemini API Key from AWS Secret Manager\n",
        "secretmanager = boto3.client('secretsmanager', region_name=region)\n",
        "response = secretmanager.get_secret_value(SecretId='geminiapikey')\n",
        "secret_json = json.loads(response[\"SecretString\"])\n",
        "api_key = secret_json[\"GEMINI_API_KEY\"]\n",
        "llm = init_chat_model(\"google_genai:gemini-2.5-flash\", google_api_key=api_key)\n",
        "\n",
        "# Structure of this AI Agent\n",
        "# User --> Extract CV --> Compare and Match between Job Requirements and CV --> Result to the next step of the recruitment process -->\n",
        "# Create Interview Email --> Create Interview Question --> End OR Create Rejection Email -> End\n",
        "\n",
        "# NODE 1: Compare and Match between Job Requirements and CV\n",
        "class compareMatchClass(BaseModel):\n",
        "    \"\"\"Compare and match between job requirements and curriculum vitae.\"\"\"\n",
        "    minimal_requirements_analysis: str = Field(description=\"Analysis of minimal requirements\")\n",
        "    preferred_requirements_analysis: str = Field(description=\"Analysis of preferred requirements\")\n",
        "    strengths: str = Field(description=\"Strengths of candidate\")\n",
        "    potential_gaps: str = Field(description=\"Potential gaps of candidate\")\n",
        "    candidate_name: str = Field(description=\"Candidate name in the CV\")\n",
        "\n",
        "compareMatch = create_agent(\n",
        "    model=llm,\n",
        "    response_format=compareMatchClass,\n",
        "    system_prompt=\"\"\"\n",
        "    You are a virtual human resources expert. You help me compare and match between curriculum vitae of candidate and AI engineer position job requirements like this :\n",
        "    1. Work across the AI lifecycle: from data preparation and model development to evaluation and deployment.\n",
        "    2. Fine-tune and integrate LLMs (like OpenAI and Gemini) into ERP workflows.\n",
        "    3. Build smart features such as recommendation engines, forecasting modules, NLP tools, and more.\n",
        "    Preferred requirements :\n",
        "    Develop and maintain scalable cloud-based AI solutions across multi-cloud platforms (AWS, GCP, Azure).\n",
        "    Write output structure like this:\n",
        "    Minimal Requirements Analysis :\n",
        "\n",
        "    Requirement 1:\n",
        "\n",
        "    Requirement n (n is the number of requirement):\n",
        "\n",
        "    Preferred Requirement Analysis :\n",
        "\n",
        "    Strengths:\n",
        "\n",
        "    Potential Gaps:\n",
        "\n",
        "    Candidate Name:\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "def compareMatchNode(state: MessagesState):\n",
        "    result = compareMatch.invoke(state)\n",
        "    return Command(update={\"messages\": result[\"messages\"]})\n",
        "\n",
        "# NODE 2: Score to the Next Step of the Recruitment Process\n",
        "class scoreNextStepClass(BaseModel):\n",
        "    \"\"\"Score value to proceed to the next step in the recruitment process.\"\"\"\n",
        "    score: int = Field(description=\"Score of candidate matched\")\n",
        "\n",
        "scoreNextStep = create_agent(\n",
        "    model=llm,\n",
        "    response_format=scoreNextStepClass,\n",
        "    system_prompt=\"\"\"\n",
        "    You are a virtual human resources expert. You help me add value from 0 until 10 to the next step of recruitment process.\n",
        "    Answer with a number between 0 and 10 ONLY without any additions. Write output structure like this:\n",
        "    1\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "def scoreNextStepNode(state: MessagesState):\n",
        "    result = scoreNextStep.invoke(state)\n",
        "    return Command(update={\"messages\": result[\"messages\"]})\n",
        "\n",
        "# NODE 3: Create Rejection/Interview Email\n",
        "class createEmailClass(BaseModel):\n",
        "    \"\"\"Create rejection email or interview invitation email for candidate.\"\"\"\n",
        "    email: str = Field(description=\"Body of email for candidate. Use `[CANDIDATE_NAME]`, `[INTERVIEW_DATE]` and `[INTERVIEW_TIME]` as placeholders for interview emails.\")\n",
        "\n",
        "createEmail = create_agent(\n",
        "    model=llm,\n",
        "    response_format=createEmailClass,\n",
        "    system_prompt=\"\"\"\n",
        "    You are a virtual human resources expert. You are help me create email in the recruitment process.\n",
        "\n",
        "    If the score is LESS THAN 7 out of 10, create a very simple rejection about failed to AI engineer position email for unsuccessful candidate.\n",
        "    Write output structure like this:\n",
        "    Hello, [CANDIDATE_NAME]\\n\n",
        "    ........\\n\n",
        "    Thanks,\\n\n",
        "    HRD of AgentCore.\n",
        "\n",
        "    But if the score is MORE THAN 7 out of 10, create an interview email for a candidate accepted to the next step to AI engineer position. Write output structure like this:\n",
        "    Hello, [CANDIDATE_NAME]\\n\n",
        "    ........\\n\n",
        "    Date : [INTERVIEW_DATE]\\n\n",
        "    Time : [INTERVIEW_TIME]\\n\n",
        "    Google Meet interview link : https://bit.ly/agentcore-interview\\n\n",
        "    ........\\n\n",
        "    Thanks,\\n\n",
        "    HRD of AgentCore.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "def createEmailNode(state: MessagesState):\n",
        "    # Extract candidate name from the compareMatch output\n",
        "    compare_match_output_str = state[\"messages\"][1].content\n",
        "    compare_match_output = json.loads(compare_match_output_str)\n",
        "    candidate_name = compare_match_output['candidate_name']\n",
        "\n",
        "    result = createEmail.invoke(state)\n",
        "    llm_output_message = result[\"messages\"][-1]\n",
        "\n",
        "    email_data = json.loads(llm_output_message.content)\n",
        "    email_body = email_data['email']\n",
        "\n",
        "    # Replace candidate name placeholder\n",
        "    email_body = email_body.replace(\"[CANDIDATE_NAME]\", candidate_name)\n",
        "\n",
        "    if \"[INTERVIEW_DATE]\" in email_body and \"[INTERVIEW_TIME]\" in email_body:\n",
        "        # Formatted interview date (today + 3 days)\n",
        "        today = datetime.date.today()\n",
        "        interview_date = today + datetime.timedelta(days=3)\n",
        "        formatted_date = interview_date.strftime(\"%d-%m-%Y\")\n",
        "\n",
        "        # Formatted interview time between 1 PM (13:00) and 4 PM (16:00)\n",
        "        hour = random.randint(13, 16)\n",
        "        minute = random.choice([0, 30])\n",
        "        if hour == 16 and minute == 30:\n",
        "            minute = 0 # if 4:30 PM was chosen, adjust to 4:00 PM\n",
        "        interview_time = datetime.time(hour, minute, 0)\n",
        "        formatted_time = interview_time.strftime(\"%I:%M %p\")\n",
        "\n",
        "        # Replace placeholders in the email body\n",
        "        email_body = email_body.replace(\"[INTERVIEW_DATE]\", formatted_date)\n",
        "        email_body = email_body.replace(\"[INTERVIEW_TIME]\", formatted_time)\n",
        "\n",
        "    updated_email_data = {\"email\": email_body}\n",
        "    updated_email_message = AIMessage(\n",
        "        content=json.dumps(updated_email_data)\n",
        "    )\n",
        "\n",
        "    new_messages = state[\"messages\"][:-1] + [updated_email_message]\n",
        "    return Command(update={\"messages\": new_messages})\n",
        "\n",
        "# NODE 4: Create Interview Questions\n",
        "class createInterviewQuestionClass(BaseModel):\n",
        "    \"\"\"Create interview questions for candidates who are accepted to the next step.\"\"\"\n",
        "    questions: str = Field(description=\"Interview questions for candidate\")\n",
        "\n",
        "createInterviewQuestion = create_agent(\n",
        "    model=llm,\n",
        "    response_format=createInterviewQuestionClass,\n",
        "    system_prompt=\"\"\"\n",
        "    You are a virtual human resources expert. You are help me create 3 interview questions about CV PDF file that already extracted.\n",
        "\n",
        "    If the score is LESS THAN 7 out of 10, DO NOT create interview questions. Write output structure like this:\n",
        "    {\\\"questions\\\": \\\"-\\\"}\n",
        "\n",
        "    But if the score is MORE THAN 7 out of 10, create 3 interview questions about CV PDF file that already extracted. Write output structure like this:\n",
        "    QUESTION 1 : ........ \\n\n",
        "    QUESTION 2 : ........ \\n\n",
        "    QUESTION 3 : ........ \\n\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "def createInterviewQuestionNode(state: MessagesState):\n",
        "    result = createInterviewQuestion.invoke(state)\n",
        "    return Command(update={\"messages\": result[\"messages\"]})\n",
        "\n",
        "# Create AI agent graph\n",
        "workflow = StateGraph(MessagesState)\n",
        "workflow.add_node(\"compareMatch\", compareMatchNode)\n",
        "workflow.add_node(\"scoreNextStep\", scoreNextStepNode)\n",
        "workflow.add_node(\"createEmail\", createEmailNode)\n",
        "workflow.add_node(\"createInterviewQuestion\", createInterviewQuestionNode)\n",
        "\n",
        "workflow.add_edge(START, \"compareMatch\")\n",
        "workflow.add_edge(\"compareMatch\", \"scoreNextStep\")\n",
        "workflow.add_edge(\"scoreNextStep\", \"createEmail\")\n",
        "workflow.add_edge(\"createEmail\", \"createInterviewQuestion\")\n",
        "workflow.add_edge(\"createInterviewQuestion\", END)\n",
        "graph = workflow.compile()\n",
        "\n",
        "# Extract CV PDF file\n",
        "def extract_cv(inputpdf):\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\") as temp_pdf_file:\n",
        "        local_file_path = temp_pdf_file.name\n",
        "        s3.download_file(\"screening-candidate\", inputpdf, local_file_path)\n",
        "    from pypdf import PdfReader\n",
        "    reader = PdfReader(local_file_path)\n",
        "    page = reader.pages[0]\n",
        "    text = page.extract_text()\n",
        "    return text\n",
        "    os.remove(local_file_path)\n",
        "\n",
        "@app.entrypoint\n",
        "def langgraph_agentcore(payload):\n",
        "    # This input is the filename of the PDF\n",
        "    pdf_filename = payload.get(\"inputpdf\")\n",
        "\n",
        "    # Extract text from the PDF file\n",
        "    user_input = extract_cv(pdf_filename)\n",
        "    events = graph.invoke({\"messages\": [(\"user\", user_input)]})\n",
        "    messages = events[\"messages\"]\n",
        "    # If write events[\"messages\"][-1].content, return questions only without email, score, etc.\n",
        "    # Create all classes to produce output like below.\n",
        "\n",
        "    # Output from Node 1\n",
        "    content_dict = json.loads(messages[1].content)\n",
        "    mra = content_dict['minimal_requirements_analysis']\n",
        "    pra = content_dict['preferred_requirements_analysis']\n",
        "    strengths = content_dict['strengths']\n",
        "    potential_gaps = content_dict['potential_gaps']\n",
        "\n",
        "    # Output from Node 2\n",
        "    content_dict_2 = json.loads(messages[2].content)\n",
        "    score = content_dict_2['score']\n",
        "\n",
        "    # Output from Node 3\n",
        "    content_dict_3 = json.loads(messages[3].content)\n",
        "    email = content_dict_3['email']\n",
        "\n",
        "    # Output from Node 4\n",
        "    content_dict_4 = json.loads(messages[4].content)\n",
        "    questions = content_dict_4['questions']\n",
        "\n",
        "    # Delete CV PDF file in S3 after processing\n",
        "    s3.delete_object(Bucket=\"screening-candidate\", Key=pdf_filename)\n",
        "    return mra, pra, strengths, potential_gaps, score, email, questions\n",
        "\n",
        "app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtJEP7vOXfY2",
        "outputId": "5abd68b3-fbe2-4a8f-88a3-8b791e0acd6c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing runtime/langgraph_agentcore.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bedrock_agentcore_starter_toolkit import Runtime\n",
        "agentcore_runtime = Runtime()\n",
        "region=\"us-west-2\"\n",
        "agent_name = \"gemini_Langgraph\"\n",
        "\n",
        "response = agentcore_runtime.configure(\n",
        "    entrypoint=\"runtime/langgraph_agentcore.py\",\n",
        "    auto_create_execution_role=True,\n",
        "    auto_create_ecr=True,\n",
        "    requirements_file=\"runtime/requirements.txt\",\n",
        "    region=region,\n",
        "    agent_name=agent_name\n",
        ")\n",
        "response"
      ],
      "metadata": {
        "id": "Fjbck5e1hbIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"AgentCore Runtime is configured.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6H6HnJcPyW4",
        "outputId": "3438009d-7cde-4a5c-8502-09b9184d2fda"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AgentCore Runtime is configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "launch_result = agentcore_runtime.launch()"
      ],
      "metadata": {
        "id": "hJnoCVNEs7vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Temporary Stop! Your AgentCore Runtime now available but don't invoke directly because S3 bucket access and Gemini API Key in AWS Secret Manager not yet added to your IAM role for AgentCore Runtime**\n",
        "\n",
        "**1. Go to AWS Secret Manager, click secret name then copy Secret ARN of Gemini API Key.**\n",
        "\n",
        "**2. Go to Amazon Bedrock AgentCore -> Agent runtime then click your agent name that already created. Click \"Version 1\" then click IAM service role of Permissions that automatically opened a new tab (e.g. AmazonBedrockAgentCoreSDKRuntime-{region-name}-{random-number-letter}).**\n",
        "\n",
        "**3. Click IAM policy name that related (e.g. BedrockAgentCoreRuntimeExecutionPolicy-{your-agent-name}).**\n",
        "\n",
        "**4. Add your Secret ARN of Gemini API Key in resource of \"secretsManager:GetSecretValue\" action then add service (S3) and add resource then click Next then click Save. DONE**\n",
        "\n",
        "# **Continue to invoke your AgentCore Runtime now**"
      ],
      "metadata": {
        "id": "EuiHfKzzdfYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Execute First Curriculum Vitae**"
      ],
      "metadata": {
        "id": "7e4V8X-q2LDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "s3 = boto3.client('s3', 'us-west-2')\n",
        "\n",
        "def upload_to_s3(file_path):\n",
        "    s3.upload_file(file_path, \"screening-candidate\", file_path)\n",
        "    return file_path"
      ],
      "metadata": {
        "id": "B8sWHaxNJxPT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e57f803b",
        "outputId": "2b3bc024-d232-4a0c-b04c-46e4058fac3d"
      },
      "source": [
        "pdf = \"Always Winner CV.pdf\"\n",
        "cvpdf = upload_to_s3(pdf)\n",
        "\n",
        "invoke_response = agentcore_runtime.invoke({\"inputpdf\": cvpdf})\n",
        "invoke_response[\"response\"]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[\"Requirement 1: The candidate demonstrates strong capabilities across the AI lifecycle, with skills in \\'Data Engineering\\', \\'MLOps\\', \\'Model Optimization\\', \\'Hyperparameter Tuning\\', and frameworks like TensorFlow, PyTorch, and Keras for model development, and tools like Docker and Kubernetes for deployment. Requirement 2: The candidate lists \\'LLMs (GPT, BERT, LLaMA)\\' and \\'API Development\\' under Generative AI, indicating foundational knowledge for fine-tuning and integration. While \\'OpenAI\\' and \\'Gemini\\' are not explicitly named, GPT is a core technology for OpenAI. However, direct experience with \\'ERP workflows\\' is not mentioned. Requirement 3: The candidate\\'s technical skills include \\'Python (TensorFlow, PyTorch, Keras, scikit-learn, Hugging Face Transformers)\\', and \\'Machine Learning: Supervised Learning, Unsupervised Learning\\', which are foundational for building smart features like recommendation engines, forecasting modules, and especially \\'NLP tools\\' (explicitly supported by Hugging Face Transformers and BE',\n",
              " 'RT).\", \"The candidate explicitly lists \\'Cloud Platforms: AWS (Sagemaker, EC2, S3), Azure (Azure ML), Google Cloud Platform (Vertex AI)\\' and \\'Tools & Libraries: Docker, Kubernetes\\', directly addressing the preferred requirement for developing and maintaining scalable cloud-based AI solutions across multi-cloud platforms.\", \"The candidate possesses a robust skill set covering a wide array of AI and ML domains, including advanced Generative AI (GANs, VAEs, Diffusion Models, LLMs), Agentic AI, and traditional Machine Learning. They have hands-on experience with major cloud platforms (AWS, Azure, GCP) and MLOps tools (Docker, Kubernetes, MLflow), which are critical for scalable solutions. Their proficiency in Python and leading ML frameworks (TensorFlow, PyTorch, Hugging Face) is a significant asset. The candidate also has direct professional experience as an AI Engineer and Junior AI Engineer.\", \"While the candidate has strong LLM knowledge, specific experience in \\'fine-tuning\\' LLMs is not explicitly stated, nor ',\n",
              " 'is direct experience with \\'integrating LLMs into ERP workflows\\'. The CV does not detail specific projects or applications demonstrating the construction of \\'recommendation engines\\' or \\'forecasting modules\\', although the underlying technical skills are present. The professional experience tenure is relatively short, with a recent transition to an AI Engineer role.\", 9, \"Hello, Always Winner\\\\n\\\\nThank you for your application for the AI Engineer position at AgentCore. We were very impressed with your qualifications and experience.\\\\n\\\\nWe would like to invite you to an interview to discuss your application further. Your interview has been scheduled for:\\\\n\\\\nDate : 08-01-2026\\\\n\\\\nTime : 04:00 PM\\\\n\\\\nGoogle Meet interview link : https://bit.ly/agentcore-interview\\\\n\\\\nWe look forward to speaking with you soon.\\\\n\\\\nThanks,\\\\n\\\\nHRD of AgentCore.\", \"QUESTION 1 : Given your experience with various Generative AI models, including LLMs like GPT, BERT, and LLaMA, could you describe a project where you applied one of these models?',\n",
              " ' Specifically, how did you approach model selection, fine-tuning (if applicable), and evaluation to achieve your project goals? QUESTION 2 : You\\'ve listed MLOps, Docker, Kubernetes, and multiple cloud platforms (AWS, Azure, GCP) as your skills. Can you walk us through a scenario where you designed and implemented a scalable MLOps pipeline for deploying an AI model into production, specifically highlighting how you leveraged these tools and platforms? QUESTION 3 : Your CV mentions \\\\\"Agentic AI\\\\\" as a skill. Could you elaborate on what Agentic AI means to you and discuss a potential use case or a theoretical project where you would apply Agentic AI principles to solve a complex problem?\"]']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "full_response_str = \"\".join(invoke_response['response'])\n",
        "parsed_response_list = ast.literal_eval(full_response_str)\n",
        "\n",
        "mra = parsed_response_list[0]\n",
        "pra = parsed_response_list[1]\n",
        "strengths = parsed_response_list[2]\n",
        "potential_gaps = parsed_response_list[3]\n",
        "score = parsed_response_list[4]\n",
        "email = parsed_response_list[5]\n",
        "questions = parsed_response_list[6]\n",
        "\n",
        "print(\"Minimal Requirements Analysis:\")\n",
        "print(mra)\n",
        "print(\"\\nPreferred Requirements Analysis:\")\n",
        "print(pra)\n",
        "print(\"\\nStrengths:\")\n",
        "print(strengths)\n",
        "print(\"\\nPotential Gaps:\")\n",
        "print(potential_gaps)\n",
        "print(\"\\nScore:\")\n",
        "print(score)\n",
        "print(\"\\nEmail:\")\n",
        "print(email)\n",
        "print(\"\\nQuestions:\")\n",
        "print(questions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0LyTlqzQ8Ke",
        "outputId": "a8ce539f-2a88-419b-a0f1-5bb71aaa03e8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimal Requirements Analysis:\n",
            "Requirement 1: The candidate demonstrates strong capabilities across the AI lifecycle, with skills in 'Data Engineering', 'MLOps', 'Model Optimization', 'Hyperparameter Tuning', and frameworks like TensorFlow, PyTorch, and Keras for model development, and tools like Docker and Kubernetes for deployment. Requirement 2: The candidate lists 'LLMs (GPT, BERT, LLaMA)' and 'API Development' under Generative AI, indicating foundational knowledge for fine-tuning and integration. While 'OpenAI' and 'Gemini' are not explicitly named, GPT is a core technology for OpenAI. However, direct experience with 'ERP workflows' is not mentioned. Requirement 3: The candidate's technical skills include 'Python (TensorFlow, PyTorch, Keras, scikit-learn, Hugging Face Transformers)', and 'Machine Learning: Supervised Learning, Unsupervised Learning', which are foundational for building smart features like recommendation engines, forecasting modules, and especially 'NLP tools' (explicitly supported by Hugging Face Transformers and BERT).\n",
            "\n",
            "Preferred Requirements Analysis:\n",
            "The candidate explicitly lists 'Cloud Platforms: AWS (Sagemaker, EC2, S3), Azure (Azure ML), Google Cloud Platform (Vertex AI)' and 'Tools & Libraries: Docker, Kubernetes', directly addressing the preferred requirement for developing and maintaining scalable cloud-based AI solutions across multi-cloud platforms.\n",
            "\n",
            "Strengths:\n",
            "The candidate possesses a robust skill set covering a wide array of AI and ML domains, including advanced Generative AI (GANs, VAEs, Diffusion Models, LLMs), Agentic AI, and traditional Machine Learning. They have hands-on experience with major cloud platforms (AWS, Azure, GCP) and MLOps tools (Docker, Kubernetes, MLflow), which are critical for scalable solutions. Their proficiency in Python and leading ML frameworks (TensorFlow, PyTorch, Hugging Face) is a significant asset. The candidate also has direct professional experience as an AI Engineer and Junior AI Engineer.\n",
            "\n",
            "Potential Gaps:\n",
            "While the candidate has strong LLM knowledge, specific experience in 'fine-tuning' LLMs is not explicitly stated, nor is direct experience with 'integrating LLMs into ERP workflows'. The CV does not detail specific projects or applications demonstrating the construction of 'recommendation engines' or 'forecasting modules', although the underlying technical skills are present. The professional experience tenure is relatively short, with a recent transition to an AI Engineer role.\n",
            "\n",
            "Score:\n",
            "9\n",
            "\n",
            "Email:\n",
            "Hello, Always Winner\n",
            "\n",
            "Thank you for your application for the AI Engineer position at AgentCore. We were very impressed with your qualifications and experience.\n",
            "\n",
            "We would like to invite you to an interview to discuss your application further. Your interview has been scheduled for:\n",
            "\n",
            "Date : 08-01-2026\n",
            "\n",
            "Time : 04:00 PM\n",
            "\n",
            "Google Meet interview link : https://bit.ly/agentcore-interview\n",
            "\n",
            "We look forward to speaking with you soon.\n",
            "\n",
            "Thanks,\n",
            "\n",
            "HRD of AgentCore.\n",
            "\n",
            "Questions:\n",
            "QUESTION 1 : Given your experience with various Generative AI models, including LLMs like GPT, BERT, and LLaMA, could you describe a project where you applied one of these models? Specifically, how did you approach model selection, fine-tuning (if applicable), and evaluation to achieve your project goals? QUESTION 2 : You've listed MLOps, Docker, Kubernetes, and multiple cloud platforms (AWS, Azure, GCP) as your skills. Can you walk us through a scenario where you designed and implemented a scalable MLOps pipeline for deploying an AI model into production, specifically highlighting how you leveraged these tools and platforms? QUESTION 3 : Your CV mentions \"Agentic AI\" as a skill. Could you elaborate on what Agentic AI means to you and discuss a potential use case or a theoretical project where you would apply Agentic AI principles to solve a complex problem?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Execute Second Curriculum Vitae**"
      ],
      "metadata": {
        "id": "7uCWUzjFFaMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf = \"Sonny Wawwak CV.pdf\"\n",
        "cvpdf = upload_to_s3(pdf)\n",
        "\n",
        "invoke_response = agentcore_runtime.invoke({\"inputpdf\": cvpdf})\n",
        "invoke_response[\"response\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNvws7rLFYSY",
        "outputId": "b57a82aa-a59d-4a88-fe3c-e4429a069430"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[\"Requirement 1: The candidate\\'s experience is entirely focused on UI/UX design, including UX research, wireframing, prototyping, and usability testing. There is no mention of data preparation, model development, evaluation, or deployment within the AI lifecycle.Requirement 2: There is no indication of experience with fine-tuning or integrating LLMs like OpenAI or Gemini, nor any work related to ERP workflows. The candidate\\'s skills are purely design-oriented.Requirement 3: The candidate\\'s background is in designing user interfaces and experiences, not in building smart features such as recommendation engines, forecasting modules, or NLP tools.\", \"There is no mention of developing or maintaining scalable cloud-based AI solutions across multi-cloud platforms like AWS, GCP, or Azure. The candidate\\'s skill set is focused on design tools and methodologies, not cloud infrastructure or AI deployment.\", \"Strong proficiency in UI/UX design principles and methodologies.Extensive experience with industry-standard desig',\n",
              " 'n tools such as Figma, Adobe XD, Sketch, and InVision.Proficient in UX research, wireframing, prototyping, and usability testing.Familiarity with Agile & Scrum workflow, which is beneficial in product development.Possesses a Bachelor’s Degree in Visual Communication Design.\", \"Significant lack of AI engineering skills and experience.No demonstrated knowledge or experience in data science, machine learning, deep learning, or any related AI technologies.No experience with programming languages commonly used in AI (e.g., Python) or AI/ML frameworks.No experience with Large Language Models (LLMs) or their integration.No experience in building AI-driven features like recommendation engines, forecasting modules, or NLP tools.No experience with cloud platforms (AWS, GCP, Azure) or developing cloud-based AI solutions.The candidate\\'s profile is entirely in UI/UX design, which is a different domain from AI engineering.\", 0, \"Hello, Sonny Wawwak\\\\n\\\\nThank you for your interest in the AI Engineer position at AgentCore. ',\n",
              " 'We appreciate you taking the time to apply.\\\\n\\\\nAfter careful consideration, we regret to inform you that we will not be moving forward with your application at this time.\\\\n\\\\nWe wish you the best in your job search.\\\\n\\\\nThanks,\\\\n\\\\nHRD of AgentCore.\", \"-\"]']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "full_response_str = \"\".join(invoke_response['response'])\n",
        "parsed_response_list = ast.literal_eval(full_response_str)\n",
        "\n",
        "mra = parsed_response_list[0]\n",
        "pra = parsed_response_list[1]\n",
        "strengths = parsed_response_list[2]\n",
        "potential_gaps = parsed_response_list[3]\n",
        "score = parsed_response_list[4]\n",
        "email = parsed_response_list[5]\n",
        "questions = parsed_response_list[6]\n",
        "\n",
        "print(\"Minimal Requirements Analysis:\")\n",
        "print(mra)\n",
        "print(\"\\nPreferred Requirements Analysis:\")\n",
        "print(pra)\n",
        "print(\"\\nStrengths:\")\n",
        "print(strengths)\n",
        "print(\"\\nPotential Gaps:\")\n",
        "print(potential_gaps)\n",
        "print(\"\\nScore:\")\n",
        "print(score)\n",
        "print(\"\\nEmail:\")\n",
        "print(email)\n",
        "print(\"\\nQuestions:\")\n",
        "print(questions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMW_lRLGHfvB",
        "outputId": "ac5290fc-6036-416c-eb16-d1bf6e318b7c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimal Requirements Analysis:\n",
            "Requirement 1: The candidate's experience is entirely focused on UI/UX design, including UX research, wireframing, prototyping, and usability testing. There is no mention of data preparation, model development, evaluation, or deployment within the AI lifecycle.Requirement 2: There is no indication of experience with fine-tuning or integrating LLMs like OpenAI or Gemini, nor any work related to ERP workflows. The candidate's skills are purely design-oriented.Requirement 3: The candidate's background is in designing user interfaces and experiences, not in building smart features such as recommendation engines, forecasting modules, or NLP tools.\n",
            "\n",
            "Preferred Requirements Analysis:\n",
            "There is no mention of developing or maintaining scalable cloud-based AI solutions across multi-cloud platforms like AWS, GCP, or Azure. The candidate's skill set is focused on design tools and methodologies, not cloud infrastructure or AI deployment.\n",
            "\n",
            "Strengths:\n",
            "Strong proficiency in UI/UX design principles and methodologies.Extensive experience with industry-standard design tools such as Figma, Adobe XD, Sketch, and InVision.Proficient in UX research, wireframing, prototyping, and usability testing.Familiarity with Agile & Scrum workflow, which is beneficial in product development.Possesses a Bachelor’s Degree in Visual Communication Design.\n",
            "\n",
            "Potential Gaps:\n",
            "Significant lack of AI engineering skills and experience.No demonstrated knowledge or experience in data science, machine learning, deep learning, or any related AI technologies.No experience with programming languages commonly used in AI (e.g., Python) or AI/ML frameworks.No experience with Large Language Models (LLMs) or their integration.No experience in building AI-driven features like recommendation engines, forecasting modules, or NLP tools.No experience with cloud platforms (AWS, GCP, Azure) or developing cloud-based AI solutions.The candidate's profile is entirely in UI/UX design, which is a different domain from AI engineering.\n",
            "\n",
            "Score:\n",
            "0\n",
            "\n",
            "Email:\n",
            "Hello, Sonny Wawwak\n",
            "\n",
            "Thank you for your interest in the AI Engineer position at AgentCore. We appreciate you taking the time to apply.\n",
            "\n",
            "After careful consideration, we regret to inform you that we will not be moving forward with your application at this time.\n",
            "\n",
            "We wish you the best in your job search.\n",
            "\n",
            "Thanks,\n",
            "\n",
            "HRD of AgentCore.\n",
            "\n",
            "Questions:\n",
            "-\n"
          ]
        }
      ]
    }
  ]
}